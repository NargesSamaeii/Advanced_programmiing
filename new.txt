# -*- coding: utf-8 -*-
"""
Created on Thu Mar 27 17:17:09 2025

@author: TIS 2
"""

import os
import time
import random
import numpy as np
import cv2
import matplotlib.pyplot as plt

import torch
import torch.optim as optim
import torchvision
import torchvision.transforms as T
from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN
from torchvision.models.detection.backbone_utils import resnet_fpn_backbone
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from pycocotools.coco import COCO

# ------------------------------------------------------------------
# 1) Check for GPU availability
if not torch.cuda.is_available():
    raise EnvironmentError("A GPU is required. Please make sure a GPU is available.")
device = torch.device("cuda")
print("✅ Code is running on GPU")

# ------------------------------------------------------------------
# 2) Set up the COCO dataset paths
train_img_dir = r"E:\COCO\train2017\train2017"
val_img_dir   = r"E:\COCO\val2017\val2017"
ann_dir       = r"E:\COCO\annotations_trainval2017\annotations"

ann_file_train = os.path.join(ann_dir, "instances_train2017.json")
ann_file_val   = os.path.join(ann_dir, "instances_val2017.json")

for path_ in [train_img_dir, val_img_dir, ann_file_train, ann_file_val]:
    if not os.path.exists(path_):
        raise FileNotFoundError(f"Path or file not found: {path_}")

print("✅ Dataset paths are set correctly!")

# ------------------------------------------------------------------
# 3) Load COCO annotations
coco_train = COCO(ann_file_train)
coco_val   = COCO(ann_file_val)

# Select 2000 images for training and 200 for validation (randomly)
train_img_ids_all = coco_train.getImgIds()
val_img_ids_all   = coco_val.getImgIds()
random.shuffle(train_img_ids_all)
random.shuffle(val_img_ids_all)
train_img_ids = train_img_ids_all[:2000]
val_img_ids   = val_img_ids_all[:200]

# ------------------------------------------------------------------
# 4) Function to load an image and its annotations (for all objects)
def load_image_and_annotations(coco, img_id, img_dir):
    """
    Loads the image and all its annotations.
    Returns None if the image/annotations do not exist or if there are no valid boxes.
    """
    img_info = coco.loadImgs(img_id)[0]
    img_path = os.path.join(img_dir, img_info["file_name"])
    if not os.path.exists(img_path):
        print(f"⚠ Image not found: {img_path}")
        return None, None

    image_bgr = cv2.imread(img_path)
    if image_bgr is None:
        print(f"⚠ Error loading image: {img_path}")
        return None, None
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

    ann_ids = coco.getAnnIds(imgIds=img_id)
    anns = coco.loadAnns(ann_ids)
    boxes = []
    labels = []
    for ann in anns:
        x, y, w, h = ann["bbox"]
        if w <= 0 or h <= 0:
            continue
        boxes.append([x, y, x + w, y + h])
        labels.append(ann["category_id"])
    # If no boxes found, discard this sample
    if len(boxes) == 0:
        return None, None

    target = {
        "boxes": torch.tensor(boxes, dtype=torch.float32),
        "labels": torch.tensor(labels, dtype=torch.int64)
    }
    return image_rgb, target

# ------------------------------------------------------------------
# 5) IoU calculation functions and metrics for evaluating all objects
def compute_iou(box1, box2):
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    inter_area = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union_area = area1 + area2 - inter_area
    return inter_area / union_area if union_area > 0 else 0.0

def evaluate_image(pred_boxes, pred_scores, pred_labels, gt_boxes, gt_labels, iou_threshold=0.5, score_threshold=0.5):
    """
    Computes the number of True Positives, False Positives, and False Negatives for all objects.
    """
    indices = [i for i, s in enumerate(pred_scores) if s >= score_threshold]
    filtered_boxes = [pred_boxes[i] for i in indices]
    filtered_labels = [pred_labels[i] for i in indices]

    tp = 0
    fp = 0
    matched_gt = [False] * len(gt_boxes)
    for i, pbox in enumerate(filtered_boxes):
        pred_label = filtered_labels[i]
        match_found = False
        for j, gbox in enumerate(gt_boxes):
            if not matched_gt[j] and pred_label == gt_labels[j]:
                if compute_iou(pbox, gbox) >= iou_threshold:
                    tp += 1
                    matched_gt[j] = True
                    match_found = True
                    break
        if not match_found:
            fp += 1
    fn = sum(1 for m in matched_gt if not m)
    return tp, fp, fn

def calc_precision_recall_f1(tp, fp, fn):
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
    return precision, recall, f1

def confusion_matrix(tp, fp, fn):
    tn = 0
    return np.array([[tp, fp],
                     [fn, tn]])

# ------------------------------------------------------------------
# 6) Build full Faster R-CNN models (trained on COCO)
def get_fasterrcnn_resnet50_full(num_classes=91):
    model = fasterrcnn_resnet50_fpn(pretrained=True)
    return model.to(device)

def get_fasterrcnn_resnet101_full(num_classes=91):
    backbone = resnet_fpn_backbone('resnet101', pretrained=True)
    model = FasterRCNN(backbone, num_classes=num_classes)
    return model.to(device)

# ------------------------------------------------------------------
# 7) Training and evaluation function (full training on COCO)
def train_and_eval(model, train_ids, val_ids, coco_train, coco_val, epochs=10, lr=1e-4, iou_thresh=0.5, score_thresh=0.5):
    params = [p for p in model.parameters() if p.requires_grad]
    optimizer = optim.Adam(params, lr=lr)
    transform = T.Compose([T.ToTensor()])

    loss_history = []
    prec_history = []
    rec_history  = []
    f1_history   = []

    t0 = time.time()
    for epoch in range(1, epochs+1):
        model.train()
        total_loss = 0
        count_img  = 0
        for img_id in train_ids:
            image_rgb, target = load_image_and_annotations(coco_train, img_id, train_img_dir)
            # Skip if image or target is empty
            if image_rgb is None or target is None or target["boxes"].size(0) == 0:
                continue
            img_tensor = transform(image_rgb).to(device)
            target = {k: v.to(device) for k, v in target.items()}
            loss_dict = model([img_tensor], [target])
            losses = sum(loss for loss in loss_dict.values())
            optimizer.zero_grad()
            losses.backward()
            optimizer.step()
            total_loss += losses.item()
            count_img += 1
        avg_loss = total_loss / count_img if count_img > 0 else 0
        loss_history.append(avg_loss)

        # Evaluation on validation set
        model.eval()
        TP = FP = FN = 0
        with torch.no_grad():
            for img_id in val_ids:
                image_rgb, target = load_image_and_annotations(coco_val, img_id, val_img_dir)
                if image_rgb is None or target is None or target["boxes"].size(0) == 0:
                    continue
                img_tensor = transform(image_rgb).to(device)
                prediction = model([img_tensor])
                pred_boxes  = prediction[0]['boxes'].cpu().numpy()
                pred_scores = prediction[0]['scores'].cpu().numpy()
                pred_labels = prediction[0]['labels'].cpu().numpy()
                gt_boxes  = target["boxes"].cpu().numpy()
                gt_labels = target["labels"].cpu().numpy()
                tp_val, fp_val, fn_val = evaluate_image(pred_boxes, pred_scores, pred_labels,
                                                        gt_boxes, gt_labels,
                                                        iou_threshold=iou_thresh,
                                                        score_threshold=score_thresh)
                TP += tp_val
                FP += fp_val
                FN += fn_val
        precision, recall, f1 = calc_precision_recall_f1(TP, FP, FN)
        prec_history.append(precision)
        rec_history.append(recall)
        f1_history.append(f1)
        print(f"[Epoch {epoch}/{epochs}] Loss: {avg_loss:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}")

    t1 = time.time()
    total_time = t1 - t0
    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Number of trainable parameters: {num_trainable_params}")
    print(f"Total training time: {total_time:.2f} seconds\n")
    return {
        "loss_history": loss_history,
        "precision_history": prec_history,
        "recall_history": rec_history,
        "f1_history": f1_history,
        "trainable_params": num_trainable_params,
        "training_time": total_time
    }

# ------------------------------------------------------------------
# 8) Train two models (fully on COCO)
epochs = 30  # Increase epochs for better accuracy

print("─── Model 1: Faster R-CNN with ResNet-50 (fully trained on COCO) ───")
model_res50 = get_fasterrcnn_resnet50_full(num_classes=91)
results_res50 = train_and_eval(model_res50, train_img_ids, val_img_ids, coco_train, coco_val, epochs=epochs)

print("─── Model 2: Faster R-CNN with ResNet-101 (fully trained on COCO) ───")
model_res101 = get_fasterrcnn_resnet101_full(num_classes=91)
results_res101 = train_and_eval(model_res101, train_img_ids, val_img_ids, coco_train, coco_val, epochs=epochs)

# ------------------------------------------------------------------
# 9) Plot comparison charts for Loss, Precision, Recall, and F1
def plot_comparison(title, data1, data2, ylabel):
    x = range(1, len(data1)+1)
    plt.figure(figsize=(6,4))
    plt.plot(x, data1, 'o--', label='ResNet-50')
    plt.plot(x, data2, 's--', label='ResNet-101')
    plt.xlabel("Epoch")
    plt.ylabel(ylabel)
    plt.title(title)
    plt.legend()
    plt.grid(True)
    plt.show()

plot_comparison("Loss Comparison", results_res50["loss_history"], results_res101["loss_history"], "Loss")
plot_comparison("Precision Comparison", results_res50["precision_history"], results_res101["precision_history"], "Precision")
plot_comparison("Recall Comparison", results_res50["recall_history"], results_res101["recall_history"], "Recall")
plot_comparison("F1 Score Comparison", results_res50["f1_history"], results_res101["f1_history"], "F1 Score")

# ------------------------------------------------------------------
# 10) Calculate and display the confusion matrix (for the ResNet-50 model as an example)
def compute_confusion_matrix(model, img_ids, coco_obj, img_dir, iou_thresh=0.5, score_thresh=0.5):
    transform = T.Compose([T.ToTensor()])
    model.eval()
    TP = FP = FN = 0
    with torch.no_grad():
        for img_id in img_ids:
            image_rgb, target = load_image_and_annotations(coco_obj, img_id, img_dir)
            if image_rgb is None or target is None:
                continue
            img_tensor = transform(image_rgb).to(device)
            prediction = model([img_tensor])
            pred_boxes  = prediction[0]['boxes'].cpu().numpy()
            pred_scores = prediction[0]['scores'].cpu().numpy()
            pred_labels = prediction[0]['labels'].cpu().numpy()
            gt_boxes  = target["boxes"].cpu().numpy()
            gt_labels = target["labels"].cpu().numpy()
            tp_val, fp_val, fn_val = evaluate_image(pred_boxes, pred_scores, pred_labels,
                                                    gt_boxes, gt_labels,
                                                    iou_threshold=iou_thresh,
                                                    score_threshold=score_thresh)
            TP += tp_val
            FP += fp_val
            FN += fn_val
    return confusion_matrix(TP, FP, FN)

cm_res50 = compute_confusion_matrix(model_res50, val_img_ids, coco_val, val_img_dir)
print("Confusion Matrix (ResNet-50) for all objects:\n", cm_res50)

# ------------------------------------------------------------------
# 11) Test and display outputs on 10 images from the validation set (val)
test_img_ids = val_img_ids[:10]
model_test = model_res50.eval()  # Example: using the ResNet-50 model
transform = T.Compose([T.ToTensor()])

for img_id in test_img_ids:
    img_info = coco_val.loadImgs(img_id)[0]
    img_path = os.path.join(val_img_dir, img_info["file_name"])
    image_bgr = cv2.imread(img_path)
    if image_bgr is None:
        continue
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    with torch.no_grad():
        img_tensor = transform(image_rgb).to(device)
        prediction = model_test([img_tensor])
    pred_boxes  = prediction[0]['boxes'].cpu().numpy()
    pred_scores = prediction[0]['scores'].cpu().numpy()
    pred_labels = prediction[0]['labels'].cpu().numpy()
    draw_img = image_rgb.copy()
    for i, box in enumerate(pred_boxes):
        if pred_scores[i] >= 0.5:  # any object with confidence >= 0.5
            x1, y1, x2, y2 = map(int, box)
            cv2.rectangle(draw_img, (x1, y1), (x2, y2), (255, 0, 0), 2)
            cv2.putText(draw_img, f"{pred_labels[i]}: {pred_scores[i]:.2f}", (x1, max(y1-5, 0)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0,0), 2)
    plt.figure(figsize=(8,6))
    plt.imshow(draw_img)
    plt.axis('off')
    plt.title(f"Val Image ID: {img_id}")
    plt.show()
