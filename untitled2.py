import torch
import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
import torchvision.transforms as T
import cv2
import numpy as np
import matplotlib.pyplot as plt
from pycocotools.coco import COCO
import os
import random

# âœ… ØªÙ†Ø¸ÛŒÙ… Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
img_dir = r"C:\Users\KARNOO\coco_data\val2017\val2017"  # Ù…Ø³ÛŒØ± Ø¬Ø¯ÛŒØ¯ ØªØµØ§ÙˆÛŒØ±
ann_file = r"C:\Users\KARNOO\coco_data\annotations\instances_val2017.json"  # Ù…Ø³ÛŒØ± Ø¬Ø¯ÛŒØ¯ annotations

# âœ… Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¶Ø±ÙˆØ±ÛŒ
if not os.path.exists(ann_file):
    raise FileNotFoundError(f"âš  ÙØ§ÛŒÙ„ annotations Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {ann_file}")

if not os.path.exists(img_dir):
    raise FileNotFoundError(f"âš  Ù¾ÙˆØ´Ù‡ ØªØµØ§ÙˆÛŒØ± val2017 Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {img_dir}")

print("âœ… Ù…Ø³ÛŒØ±Ù‡Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯!")

# ðŸš€ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø¯Ø§Ø¯Ù‡ COCO
coco = COCO(ann_file)

# ðŸŽ¯ Ú¯Ø±ÙØªÙ† ØªØµØ§ÙˆÛŒØ± Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ù„Ø§Ø³ Ø®ÙˆØ¯Ø±Ùˆ (category_id = 3)
category_id = 3  # Ú©Ù„Ø§Ø³ Ø®ÙˆØ¯Ø±Ùˆ Ø¯Ø± COCO
image_ids = coco.getImgIds(catIds=[category_id])
random.shuffle(image_ids)

# ðŸ—ï¸ Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Faster R-CNN
def get_model():
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights="COCO_V1")
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 91)  # 91 Ú©Ù„Ø§Ø³ COCO
    return model

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = get_model().to(device)
model.train()

# âš™ï¸ ØªØ§Ø¨Ø¹ ØªØ¨Ø¯ÛŒÙ„ ØªØµØ§ÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ PyTorch
transform = T.Compose([T.ToTensor()])

# ðŸŽ“ **Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ø±Ùˆ**
epochs = 20
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
losses = []

for epoch in range(epochs):
    total_loss = 0
    for img_id in image_ids[:20]:  # Ø¢Ù…ÙˆØ²Ø´ ÙÙ‚Ø· Ø±ÙˆÛŒ 20 ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ ØªØ³Øª
        img_info = coco.loadImgs(img_id)[0]
        img_path = os.path.join(img_dir, img_info["file_name"])

        # âœ… Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø³ÛŒØ± ØªØµÙˆÛŒØ± Ù‚Ø¨Ù„ Ø§Ø² Ø®ÙˆØ§Ù†Ø¯Ù†
        if not os.path.exists(img_path):
            print(f"âš  ØªØµÙˆÛŒØ± ÛŒØ§ÙØª Ù†Ø´Ø¯: {img_path}")
            continue

        # ðŸ–¼ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ ØªØµÙˆÛŒØ±
        image = cv2.imread(img_path)
        if image is None:
            print(f"âš  Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ ØªØµÙˆÛŒØ±: {img_path}")
            continue
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        img_tensor = transform(image).to(device)

        # ðŸ“Œ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ Ùˆ Ø¬Ø¹Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯Ú©Ù†Ù†Ø¯Ù‡
        ann_ids = coco.getAnnIds(imgIds=img_id, catIds=[category_id])
        anns = coco.loadAnns(ann_ids)
        
        boxes = []
        labels = []
        for ann in anns:
            x, y, w, h = ann["bbox"]
            boxes.append([x, y, x + w, y + h])
            labels.append(category_id)

        if len(boxes) == 0:
            print(f"âš  Ù‡ÛŒÚ† Ø®ÙˆØ¯Ø±ÙˆÛŒÛŒ Ø¯Ø± Ø§ÛŒÙ† ØªØµÙˆÛŒØ± ÛŒØ§ÙØª Ù†Ø´Ø¯: {img_path}")
            continue

        target = {
            "boxes": torch.tensor(boxes, dtype=torch.float32).to(device),
            "labels": torch.tensor(labels, dtype=torch.int64).to(device),
        }

        # âœ… Ù…Ø­Ø§Ø³Ø¨Ù‡ Loss Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„
        loss_dict = model([img_tensor], [target])
        loss = sum(loss for loss in loss_dict.values())
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(image_ids[:20])
    losses.append(avg_loss)
    print(f"ðŸŽ¯ Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}")

# **ðŸ“Š Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± ØªØºÛŒÛŒØ±Ø§Øª Ø®Ø·Ø§**
plt.figure(figsize=(8, 5))
plt.plot(range(1, epochs + 1), losses, marker='o', linestyle='-', color='b', label='Total Loss')
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training Loss Over Epochs")
plt.legend()
plt.grid()
plt.show()

# **ðŸš— ØªØ³Øª Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ú†Ù†Ø¯ ØªØµÙˆÛŒØ± Ø¬Ø¯ÛŒØ¯**
model.eval()

def test_model(image_id):
    img_info = coco.loadImgs(image_id)[0]
    img_path = os.path.join(img_dir, img_info["file_name"])

    # âœ… Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø³ÛŒØ± ØªØµÙˆÛŒØ±
    if not os.path.exists(img_path):
        print(f"âš  ØªØµÙˆÛŒØ± ØªØ³Øª ÛŒØ§ÙØª Ù†Ø´Ø¯: {img_path}")
        return

    # ðŸ–¼ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ±
    image = cv2.imread(img_path)
    if image is None:
        print(f"âš  Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± ØªØ³Øª: {img_path}")
        return

    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    img_tensor = transform(image).to(device)

    # ðŸš€ Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ø±ÙˆÛŒ ØªØµÙˆÛŒØ±
    with torch.no_grad():
        prediction = model([img_tensor])

    boxes = prediction[0]['boxes'].cpu().numpy()
    scores = prediction[0]['scores'].cpu().numpy()
    labels = prediction[0]['labels'].cpu().numpy()

    # âœ… Ù†Ù…Ø§ÛŒØ´ ØªØ´Ø®ÛŒØµâ€ŒÙ‡Ø§
    threshold = 0.5
    for i in range(len(boxes)):
        if scores[i] > threshold and labels[i] == category_id:
            x1, y1, x2, y2 = boxes[i].astype(int)
            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)
            cv2.putText(image, f"Car: {scores[i]:.2f}", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    plt.figure(figsize=(10, 8))
    plt.imshow(image)
    plt.axis("off")
    plt.title(f"Detected Cars - Image ID: {image_id}")
    plt.show()

# âœ… Ù†Ù…Ø§ÛŒØ´ Ø³Ù‡ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² ØªØµØ§ÙˆÛŒØ± ØªØ³ØªÛŒ
for img_id in image_ids[:3]:
    test_model(img_id)